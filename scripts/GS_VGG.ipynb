{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXrtyCMN4Emj",
        "outputId": "84c7017e-6b69-4eb9-d4cc-094d9545e8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary packages\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "K_OHbjSx4jRJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = os.path.join(\"/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/entropyGraph/Images/entropy_graph_compressed\")\n",
        "\n",
        "folders = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']\n",
        "\n",
        "# capturing training data and labels into respective lists\n",
        "images = []\n",
        "gs_image_labels = []\n",
        "img_count = 0\n",
        "image_labels = []\n",
        "count = 0\n",
        "x_gs_train, x_gs_test, y_gs_train, y_gs_test = [], [], [], []\n",
        "\n",
        "for folder in folders:\n",
        "    sub_folder = os.path.join(data, folder)\n",
        "    print(\"Image count\",img_count)\n",
        "    print(sub_folder)\n",
        "    count += 1\n",
        "    img_count = 0\n",
        "    for file_ in os.listdir(sub_folder):\n",
        "        img_path = os.path.join(sub_folder, file_)\n",
        "        #print(img_path)\n",
        "        with Image.open(img_path) as img:\n",
        "            img = img.resize((224,224))\n",
        "            img_array = np.array(img)\n",
        "            images.append(img_array)\n",
        "            image_labels.append(folder)\n",
        "        img_count += 1\n",
        "    x_train, x_test, y_train, y_test = train_test_split(images, image_labels, test_size=0.3, random_state=42)\n",
        "    for ele in x_train:\n",
        "      x_gs_train.append(ele)\n",
        "    for ele in y_train:\n",
        "      y_gs_train.append(ele)\n",
        "    for ele in x_test:\n",
        "      x_gs_test.append(ele)\n",
        "    for ele in y_test:\n",
        "      y_gs_test.append(ele)\n",
        "    print(len(x_gs_train))\n",
        "    print(\"Length of train data\",len(x_train))\n",
        "    x_train.clear()\n",
        "    x_test.clear()\n",
        "    y_train.clear()\n",
        "    y_test.clear()\n",
        "    images.clear()\n",
        "    image_labels.clear()\n",
        "\n",
        "print(\"Number of images:\", img_count)\n",
        "print(\"Number of folders:\", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Wmz8M6Mq43Hb",
        "outputId": "6891f632-a036-4036-cb8b-9da9c832f525"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image count 0\n",
            "/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/entropyGraph/Images/entropy_graph_compressed/Lollipop\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d55bb8fb13ee>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mimg_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(img_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_gs_train)\n",
        "x_test = np.array(x_gs_test)\n",
        "y_train = np.array(y_gs_train)\n",
        "y_test = np.array(y_gs_test)"
      ],
      "metadata": {
        "id": "_YpWa2arabx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "SlnE3To5aoPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode labels from text to integers.\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "le.fit(y_train)\n",
        "y_train = le.transform(y_train)\n",
        "\n",
        "le.fit(y_test)\n",
        "y_test = le.transform(y_test)"
      ],
      "metadata": {
        "id": "TBHbNUMlf74T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "Ex5F3y6qgytZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\",x_train.shape)\n",
        "print(\"y_train shape:\",y_train.shape)\n",
        "print(\"X_test shape:\",x_test.shape)\n",
        "print(\"y_test shape:\",y_test.shape)"
      ],
      "metadata": {
        "id": "Ac_Iv3Dkg7dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encode y values for neural network.\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "2fuqmYF1j6xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "id": "TIuVWvsaiqui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    model_1 = Sequential()\n",
        "\n",
        "    vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze the weights of all layers in the VGG16 model\n",
        "    for layer in vgg.layers:\n",
        "        layer.trainable = False\n",
        "    # Add the VGG16 model to your own model\n",
        "    model_1.add(vgg)\n",
        "    # Add the flatten layer\n",
        "    model_1.add(Flatten())\n",
        "    # Add the dense layer\n",
        "    model_1.add(Dense(units=hp.Int('dense_units', min_value=32, max_value=512, step=32),activation='relu'))\n",
        "    model_1.add(Dropout(hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "    # Add the output layer\n",
        "    model_1.add(Dense(units=9, activation='softmax', name='output_layer'))\n",
        "    # Compile the model\n",
        "    model_1.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model_1"
      ],
      "metadata": {
        "id": "NbALZP5iigUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='/content/drive/MyDrive/Big2015/Hex_vgg(TT5)/Tuned_model',\n",
        "    project_name='big_hex_img_vgg',\n",
        "    overwrite = True\n",
        ")"
      ],
      "metadata": {
        "id": "LtmgbBnmimV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train,\n",
        "             epochs=10,\n",
        "             validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "beaVUMmYiw0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "RMuSAP0Bi10T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_hyperparameters\n",
        "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "woqiVSrlFNCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-tranining the model\n",
        "\n",
        "history = best_model.fit(x_train, y_train, epochs=30,validation_data=(x_test, y_test),initial_epoch=3)"
      ],
      "metadata": {
        "id": "Sq4meHp9FP9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = best_model.evaluate(x_test,y_test)\n",
        "\n",
        "# model loss and accuracy\n",
        "print(\"model loss:\",result[0])\n",
        "print(\"model accuracy\",result[1])"
      ],
      "metadata": {
        "id": "-Rw4Q0HQFSHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the cnn model\n",
        "best_model.save('/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/grayScale/Models/VGG16/EG_vgg.keras')"
      ],
      "metadata": {
        "id": "jg9IY-10FUf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "metadata": {
        "id": "MbWTWx3GFXwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "sfD6Ro4AFbf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "KjvmbjkTFiU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9pM5uD0cFkgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "NnLuFsK0FmBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = []\n",
        "y_actual = []\n",
        "for i in range(0,len(x_test)):\n",
        "    start_time = time.time()\n",
        "    y_actual.append(np.argmax(y_test[i]))\n",
        "    y_predict.append(np.argmax(best_model.predict(x_test[i].reshape(1,224,224,3))))\n",
        "    end_time = time.time()\n",
        "\n",
        "predicted_time = start_time - end_time"
      ],
      "metadata": {
        "id": "Pkfa-OdOFw71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prediction Time: \", predicted_time)"
      ],
      "metadata": {
        "id": "peoyj671F7gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "id": "nyD2OIpxF_qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "label = np.arange(9)\n",
        "matrix = confusion_matrix(y_predict,y_actual,normalize = 'true')\n",
        "print(matrix)"
      ],
      "metadata": {
        "id": "cBkgsbBfGEDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing confusion matrix\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(40,30))\n",
        "sns.set(font_scale=1.8)\n",
        "fx=sns.heatmap(matrix, annot=True,fmt='.4f',cmap=\"GnBu\")\n",
        "fx.set_title('Confusion Matrix \\n');\n",
        "fx.set_xlabel('\\n Predicted Values\\n')\n",
        "fx.set_ylabel('Actual Values\\n');\n",
        "fx.xaxis.set_ticklabels(folders)\n",
        "fx.yaxis.set_ticklabels(folders)\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/entropyGraph/Confusion_matrix/\"\n",
        "file_name = \"Confusion_Matrix_Entropy[new].png\"\n",
        "plt.savefig(file_path + file_name)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B7Vz_j88GFvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classficaton report\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "report_dict = classification_report(y_actual,y_predict,target_names=folders, output_dict=True)\n",
        "\n",
        "# Convert the dictionary to a Pandas DataFrame\n",
        "report_df = pd.DataFrame.from_dict(report_dict).transpose()\n",
        "\n",
        "total_support = report_df['support'].sum()\n",
        "report_df.loc['accuracy', 'support'] = report_df.loc['Lollipop', 'support'] + report_df.loc['Kelihos_ver3', 'support'] + report_df.loc['Gatak', 'support'] +report_df.loc['Kelihos_ver1', 'support'] + report_df.loc['Obfuscator.ACY', 'support'] + report_df.loc['Simda', 'support'] + report_df.loc['Tracur', 'support'] + report_df.loc['Vundo', 'support'] + report_df.loc['Ramnit', 'support']\n",
        "\n",
        "#Set the path and filename for the CSV file\n",
        "file_path = \"/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/entropyGraph/Classification reports/\"\n",
        "file_name = \"classification_report_hex_vgg[new].csv\"\n",
        "\n",
        "# Save the DataFrame to a CSV file in Google Drive\n",
        "report_df.to_csv(file_path + file_name)"
      ],
      "metadata": {
        "id": "9o4PiMRhGI3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report_df)"
      ],
      "metadata": {
        "id": "kv3ptll3GNPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.0981"
      ],
      "metadata": {
        "id": "o0sQ9hYbGPnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znxBw6Bvpjp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}