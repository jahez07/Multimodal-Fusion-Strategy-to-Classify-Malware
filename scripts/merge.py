# Import necessary packages

import os
import glob
import cv2
import time
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import tensorflow as tf
from keras import models
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix
from keras.layers import Dense
from keras.models import Sequential,Model
from tensorflow.keras.layers import Dense,Activation,Flatten,Dropout,Input,concatenate, add,Flatten,minimum,maximum,average, ActivityRegularization, Dot
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report
from keras.regularizers import l2
from tensorflow.keras.layers import Dot
import pandas as pd
from tensorflow.keras.layers import concatenate

"""##**Gray Scale Data**"""

data = os.path.join("/Grayscale")

folders = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# capturing training data and labels into respective lists
images = []
gs_image_labels = []

for folder in folders:
    sub_folder = os.path.join(data, folder)
    print(sub_folder)
    for file_ in os.listdir(sub_folder):
        img_path = os.path.join(sub_folder, file_)
        with Image.open(img_path) as img:
            img = img.resize((224,224))
            img_array = np.array(img)
            images.append(img_array)
            gs_image_labels.append(folder)

# convert the list into arrays
gs_images = np.array(images)
gs_image_labels = np.array(gs_image_labels)

from sklearn.model_selection import train_test_split

x_gs_train, x_gs_test, y_gs_train, y_gs_test = train_test_split(gs_images, gs_image_labels, test_size=0.3, random_state=42)

# Check the shapes of the resulting datasets
print("Training data shape:", x_gs_train.shape)
print("Training label shape:", y_gs_train.shape)
print("Testing data shape:", x_gs_test.shape)
print("Testing label shape:", y_gs_test.shape)

#Encode labels from text to integers.
from sklearn import preprocessing

le = preprocessing.LabelEncoder()

le.fit(y_gs_train)
y_gs_train_encoded = le.transform(y_gs_train) #train labels

le.fit(y_gs_test)
y_gs_test_encoded = le.transform(y_gs_test) #test labels

# One-hot encode the labels
y_gs_train_encoded = tf.keras.utils.to_categorical(y_gs_train_encoded, num_classes=9)
y_gs_test_encoded = tf.keras.utils.to_categorical(y_gs_test_encoded, num_classes = 9)

hex_image_arr = x_gs_test

hex_npy = "hex_image.npy"
np.save(hex_npy, hex_image_arr)

hex_in = Input(shape = (224,224,3), name = 'hex_in')

# Designing the first VGG16 model for Hex Images
hex_ = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))

hex_._name = 'hex_vgg'

# Freeze the layers in the VGG16 model so that they are not trained during training
for layer in hex_.layers:
  layer.trainable = False

# Pass the input through the VGG16 model
hex_vgg_output = hex_(hex_in)

# Add a classifier on top of the model
#hex_model = Flatten(name = 'hex_flatten')(hex_vgg_output)
hex_model = Dense(512, activation='relu', name='hex_dense')(hex_vgg_output)

"""##**Entropy Graph**

###**Loading Data**
"""

eg_data = os.path.join("/Entropy")

folders = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# capturing training data and labels into respective lists
images = []
eg_image_labels = []

for folder in folders:
    sub_folder = os.path.join(eg_data, folder)
    print(sub_folder)
    for file_ in os.listdir(sub_folder):
        img_path = os.path.join(sub_folder, file_)
        with Image.open(img_path) as img:
            img = img.resize((224,224))
            img_array = np.array(img)
            images.append(img_array)
            eg_image_labels.append(folder)

# convert the list into arrays
eg_images = np.array(images)
eg_image_labels = np.array(eg_image_labels)

"""###**Splitting Data**"""

from sklearn.model_selection import train_test_split

x_eg_train, x_eg_test, y_eg_train, y_eg_test = train_test_split(eg_images, eg_image_labels, test_size=0.3, random_state=42)

# Check the shapes of the resulting datasets
print("Training data shape:", x_eg_train.shape)
print("Training label shape:", y_eg_train.shape)
print("Testing data shape:", x_eg_test.shape)
print("Testing label shape:", y_eg_test.shape)

"""###**Encoding the Labels**"""

#Encode labels from text to integers.
from sklearn import preprocessing

le = preprocessing.LabelEncoder()

le.fit(y_eg_train)
y_eg_train_encoded = le.transform(y_eg_train) #train labels

le.fit(y_eg_test)
y_eg_test_encoded = le.transform(y_eg_test) #test labels

# One-hot encode the labels
y_eg_train_encoded = tf.keras.utils.to_categorical(y_eg_train_encoded, num_classes=9)
y_eg_test_encoded = tf.keras.utils.to_categorical(y_eg_test_encoded, num_classes = 9)

"""###**Storing Test Data**"""

eg_image_arr = x_eg_test

eg_npy = "eg_image.npy"
np.save(eg_npy, eg_image_arr)

eg_image_arr.shape

eg_in = Input(shape = (224,224,3), name = 'eg_in')

"""###**Entropy VGG16 Model**"""

# Designing the first VGG16 model for Entropy Images
eg_ = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))

eg_._name = 'eg_vgg'

# Freeze the layers in the VGG16 model so that they are not trained during training
for layer in eg_.layers:
  layer.trainable = False

# Pass the input through the VGG16 model
eg_vgg_output = eg_(eg_in)

# Add a classifier on top of the model
#eg_model = Flatten(name = 'eg_flatten')(eg_vgg_output)
eg_model = Dense(512, activation='relu', name='eg_dense')(eg_vgg_output)

"""##**SimHash**

###**Loading Data**
"""

sh_data = os.path.join("/Simhash")

folders = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# capturing training data and labels into respective lists
images = []
sh_image_labels = []

for folder in folders:
    sub_folder = os.path.join(sh_data, folder)
    print(sub_folder)
    for file_ in os.listdir(sub_folder):
        img_path = os.path.join(sub_folder, file_)
        with Image.open(img_path) as img:
            img = img.resize((224,224))
            img_array = np.array(img)
            images.append(img_array)
            sh_image_labels.append(folder)

# convert the list into arrays
sh_images = np.array(images)
sh_image_labels = np.array(sh_image_labels)

"""###**Splitting Data**"""

from sklearn.model_selection import train_test_split

x_sh_train, x_sh_test, y_sh_train, y_sh_test = train_test_split(sh_images, sh_image_labels, test_size=0.3, random_state=42)

# Check the shapes of the resulting datasets
print("Training data shape:", x_sh_train.shape)
print("Training label shape:", y_sh_train.shape)
print("Testing data shape:", x_sh_test.shape)
print("Testing label shape:", y_sh_test.shape)

"""###**Encoding the Labels**"""

#Encode labels from text to integers.
from sklearn import preprocessing

le = preprocessing.LabelEncoder()

le.fit(y_sh_train)
y_sh_train_encoded = le.transform(y_sh_train) #train labels

le.fit(y_sh_test)
y_sh_test_encoded = le.transform(y_sh_test) #test labels

# One-hot encode the labels
y_sh_train_encoded = tf.keras.utils.to_categorical(y_sh_train_encoded, num_classes=9)
y_sh_test_encoded = tf.keras.utils.to_categorical(y_sh_test_encoded, num_classes = 9)

"""###**Storing the Test Data**"""

sh_image_arr = x_sh_test

sh_npy = "sh_image.npy"
np.save(sh_npy, sh_image_arr)

sh_in = Input(shape = (224,224,3), name = 'sh_in')

"""###**SimHash VGG16 Model**"""

# Designing the first VGG16 model for Entropy Images
sh_ = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))

sh_._name = 'sh_vgg'

# Freeze the layers in the VGG16 model so that they are not trained during training
for layer in sh_.layers:
  layer.trainable = False

# Pass the input through the VGG16 model
sh_vgg_output = sh_(sh_in)

# Add a classifier on top of the model
sh_model = Dense(512, activation='relu', name='sh_dense')(sh_vgg_output)
#sh_model = Flatten(name = 'sh_flatten')(sh_vgg_output)

"""#**Model Merge**

##**GS+EG**

###**GS+EG(MAX)**
"""

# Concatenate the output of the 2 models
merged = maximum([hex_model, eg_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [hex_in, eg_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_eg_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_eg_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/GS_EG_vgg(max).pkl')

import matplotlib.pyplot as plt
import pandas as pd

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

import time

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)

test_images = [np.load('hex_image.npy'),np.load('eg_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

# Print the classification report
print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "gs_eg_max_classification_report.csv"

report.to_csv(file_path + file_name)

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "GS_EG_Max_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

"""###**GS+EG(ADD)**"""

# Concatenate the output of the 2 models
merged = add([hex_model, eg_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [hex_in, eg_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_eg_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_eg_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/GS_EG_vgg(add).keras')

import matplotlib.pyplot as plt
import pandas as pd

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)

#test_images = [hex_x_test, en_x_test]


test_images = [np.load('hex_image.npy'),np.load('eg_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "GS_EG_add_classification_report.csv"

report.to_csv(file_path + file_name)

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/Merge/ConfusionMetrics/"
file_name = "GS_EG_ADD_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

"""###**GS+EG(AVG)**"""

# Concatenate the output of the 2 models
merged = average([hex_model, eg_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [hex_in, eg_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_eg_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_eg_test], y_gs_test_encoded)
)

# Saving the Model
merged_model.save('/Models/GS_EG_vgg(average).keras')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)

#test_images = [hex_x_test, en_x_test]


test_images = [np.load('hex_image.npy'),np.load('eg_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/Merge/ClassificationReports/"
file_name = "GS_EG_avg_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/ConfusionMetrics/"
file_name = "GS_EG_AVERAGE_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**GS+EG(CONCAT)**"""

# Concatenate the output of the 2 models
merged = concatenate([hex_model, eg_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(512, activation = 'relu')(merged)
dense2 = Dense(256, activation = 'relu')(dense1)
dense3 = Dense(128, activation = 'relu')(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [hex_in, eg_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_eg_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_eg_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/GS_EG_vgg(concat).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('hex_image.npy'),np.load('eg_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "GS_EG_concat_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "GS_EG_CONCAT_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""##**GS+SH**

###**GS+SH(ADD)**
"""

# Concatenate the output of the 2 models
merged = add([hex_model, sh_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [hex_in, sh_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/GS_SH_vgg(add).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)

#test_images = [hex_x_test, en_x_test]


test_images = [np.load('hex_image.npy'),np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/Merge/ClassificationReports/"
file_name = "GS_SH_add_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "GS_SH_ADD_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**GS+SH(AVG)**"""

# Concatenate the output of the 2 models
merged = average([hex_model, sh_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [hex_in, sh_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_sh) model
merged_model.save('/Models/GS_SH_vgg(average).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('hex_image.npy'),np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "GS_SH_average_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "GS_SH_AVERAGE_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**GS+SH(MAX)**"""

# Concatenate the output of the 2 models
merged = maximum([hex_model, sh_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [hex_in, sh_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/GS_SH_vgg(maximum).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('hex_image.npy'),np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "GS_SH_maximum_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "GS_SH_MAXIMUM_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**GS+SH(CONCAT)**"""

# Concatenate the output of the 2 models
merged = concatenate([hex_model, sh_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [hex_in, sh_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/GS_SH_vgg(concat).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('hex_image.npy'), np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "GS_SH_concat_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "GS_EG_SH_CONCAT_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""##**EG+SH**

###**EG+SH(ADD)**
"""

# Concatenate the output of the 2 models
merged = add([eg_model, sh_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [eg_in, sh_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_eg_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_eg_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/EG_SH_vgg(add).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('eg_image.npy'),np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "EG_SH_add_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "EG_SH_ADD_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**EG+SH(AVG)**"""

# Concatenate the output of the 2 models
merged = average([eg_model, sh_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [eg_in, sh_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_eg_train, x_sh_train],
    y_gs_train_encoded,
    epochs=40,
    batch_size=32,
    verbose=1,
    validation_data=([x_eg_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/EG_SH_vgg(average).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

import time

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('eg_image.npy'),np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "EG_SH_average_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "EG_SH_AVERAGE_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**EG+SH(MAX)**"""

# maximize the output of the 2 models
merged = maximum([eg_model, sh_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(256, activation = 'relu')(merged)
dense2 = Dense(128, activation = 'relu')(dense1)
dense3 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense2)
output = Dense(9, activation = 'softmax')(dense3)

# Define the model
merged_model = Model(inputs = [eg_in, sh_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_eg_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_eg_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/EG_SH_vgg(maximum).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('eg_image.npy'),np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "EG_SH_maximum_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "EG_SH_MAXIMUM_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**EG+SH(CONCAT)**"""

# Concatenate the output of the 2 models
merged = concatenate([eg_model, sh_model])

# Add one or more dense layers on top of the merged output
dense1 = Dense(512, activation = 'relu')(merged)
dense2 = Dense(256, activation = 'relu')(dense1)
dense3 = Dense(128, activation = 'relu')(dense2)
dense4 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense3)
output = Dense(9, activation = 'softmax')(dense4)

# Define the model
merged_model = Model(inputs = [eg_in, sh_in], outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_eg_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_eg_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('Models/EG_SH_vgg(concat).pkl')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('eg_image.npy'), np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "EG_SH_concat_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "EG_SH_CONCAT_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""##**GS+EG+SH**

###**GS+EG+SH(ADD)**
"""

# Concatenate the output of the 2 models
merged = add([hex_model, eg_model, sh_model])

# Add one or more dense layers on top of the merged output

# Add 1D convolutional layers
conv1 = Conv1D(filters=515, kernel_size=3, strides=1, activation='relu')(merged)
flatten = Flatten()(conv1)
dense1 = Dense(512, activation = 'relu')(flatten)
dense2 = Dense(256, activation = 'relu')(dense1)
dense3 = Dense(128, activation = 'relu')(dense2)
dense4 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense3)
output = Dense(9, activation = 'softmax')(dense4)

# Define the model
merged_model = Model(inputs = hex_in, outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_eg_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_eg_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/GS_EG_SH_vgg(ADD_NEW).keras')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.ylim(0, 1)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('hex_image.npy'),np.load('eg_image.npy'), np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/ClassificationReports/"
file_name = "GS_EG_SH_add_classification_report[NEW].csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/ConfusionMetrics/"
file_name = "GS_EG_SH_ADD_Confusion_Matrix[NEW].png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**GS+EG+SH(AVERAGE)**"""

# Concatenate the output of the 2 models
merged = average([hex_model, eg_model, sh_model])

# Add one or more dense layers on top of the merged output

# Add 1D convolutional layers
conv1 = Conv1D(filters=515, kernel_size=3, strides=1, activation='relu')(merged)
flatten = Flatten()(conv1)
dense1 = Dense(512, activation = 'relu')(flatten)
dense2 = Dense(256, activation = 'relu')(dense1)
dense3 = Dense(128, activation = 'relu')(dense2)
dense4 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense3)
output = Dense(9, activation = 'softmax')(dense4)

# Define the model
merged_model = Model(inputs = hex_in, outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_eg_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_eg_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/Models/GS_EG_SH_vgg(AVG_NEW).keras')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.ylin(0,1)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('hex_image.npy'),np.load('eg_image.npy'), np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/ClassificationReports/"
file_name = "GS_EG_SH_average_classification_report.csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/ConfusionMetrics/"
file_name = "GS_EG_SH_AVERAGE_Confusion_Matrix.png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**GS+EG+SH(MAXIMUM)**"""

# Concatenate the output of the 2 models
merged = maximum([hex_model, eg_model, sh_model])

# Add one or more dense layers on top of the merged output

# Add 1D convolutional layers
conv1 = Conv1D(filters=515, kernel_size=3, strides=1, activation='relu')(merged)
flatten = Flatten()(conv1)
dense1 = Dense(512, activation = 'relu')(flatten)
dense2 = Dense(256, activation = 'relu')(dense1)
dense3 = Dense(128, activation = 'relu')(dense2)
dense4 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense3)
output = Dense(9, activation = 'softmax')(dense4)

# Define the model
merged_model = Model(inputs = hex_in, outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_eg_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_eg_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/Models/GS_EG_SH_vgg(MAX_NEW).keras')

history_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.ylim(0,1)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('hex_image.npy'),np.load('eg_image.npy'), np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/ClassificationReports/"
file_name = "GS_EG_SH_maximum_classification_report[NEW].csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/ConfusionMetrics/"
file_name = "GS_EG_SH_MAXIMUM_Confusion_Matrix[NEW].png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

"""###**GS+EG+SH(CONCAT)**"""

from tensorflow.keras.layers import concatenate, Conv1D, MaxPooling1D, Flatten
from hyperopt import hp



# Concatenate the output of the 2 models
merged = concatenate([hex_model, eg_model, sh_model])

# Add one or more dense layers on top of the merged output

# Add 1D convolutional layers
conv1 = Conv1D(filters=515, kernel_size=3, strides=1, activation='relu')(merged)
flatten = Flatten()(conv1)
dense1 = Dense(512, activation = 'relu')(flatten)
dense2 = Dense(256, activation = 'relu')(dense1)
dense3 = Dense(128, activation = 'relu')(dense2)
dense4 = Dense(64, activation = 'relu',kernel_regularizer = l2(0.01))(dense3)
output = Dense(9, activation = 'softmax')(dense4)

# Define the model
merged_model = Model(inputs = hex_in, outputs = output, name = 'merged_model')

# Compile the model
merged_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = merged_model.fit(
    [x_gs_train, x_eg_train, x_sh_train],
    y_gs_train_encoded,
    epochs=50,
    batch_size=32,
    verbose=1,
    validation_data=([x_gs_test, x_eg_test, x_sh_test], y_gs_test_encoded)
)

# saving the first (hex_en) model
merged_model.save('/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/Models/GS_EG_SH_vgg(concat[conv]).keras')

Ihistory_data = pd.DataFrame(history.history)

# Create the plot
plt.plot(history_data)
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.title('Training History')
plt.grid(True)
plt.legend(history_data.columns)
plt.ylim(0,1)
plt.show()

from sklearn.metrics import classification_report

y_true = y_gs_test_encoded  # True labels (ground truth)


#test_images = [hex_x_test, en_x_test]

test_images = [np.load('hex_image.npy'),np.load('eg_image.npy'), np.load('sh_image.npy')]
start_time = time.time()
y_pred = merged_model.predict(test_images)
end_time = time.time()
print(f"Prediction time: {end_time - start_time}")

# Convert probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert one-hot encoded true labels to class labels
y_true_classes = np.argmax(y_true, axis=1)

classes = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# Generate the classification report
report_dict = classification_report(y_true_classes, y_pred_classes, target_names=classes, output_dict=True)
report = pd.DataFrame(report_dict).transpose()

print(report)

#Set the path and filename for the CSV file
file_path = "/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/ClassificationReports/"
file_name = "GS_EG_SH_concat_classification_report[NEW].csv"

report.to_csv(file_path + file_name)

from sklearn.metrics import confusion_matrix

label = np.arange(9)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes, normalize = 'true')
print(conf_matrix)

# Visualizing confusion matrix
import seaborn as sns

plt.figure(figsize=(40,30))
sns.set(font_scale=1.8)
fx=sns.heatmap(conf_matrix, annot=True,fmt='.4f',cmap="GnBu")
fx.set_title('Confusion Matrix \n');
fx.set_xlabel('\n Predicted Values\n')
fx.set_ylabel('Actual Values\n');
fx.xaxis.set_ticklabels(folders)
fx.yaxis.set_ticklabels(folders)

file_path = "/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/ConfusionMetrics/"
file_name = "GS_EG_SH_CONCAT_Confusion_Matrix[NEW].png"
plt.savefig(file_path + file_name)

plt.show()

accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, and F1-score
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-score: {f1:.4f}')
print(f'Macro F1-score: {macro_f1:.4f}')

