import os
import time
import glob
import numpy as np
import pandas as pd
from PIL import Image
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn import preprocessing
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications.vgg16 import preprocess_input
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, classification_report

#              L O A D I  N G  A L L   G E N E R A T E D  M O D A L I T I E S

# Grayscale 
imagedir = "/content/drive/MyDrive/Jahez_Vinod_2023/DMD(MainProject)/GAN/SelectedGenData/Grayscale"

cur_dir = os.getcwd()
os.chdir(imagedir)  # the parent folder with sub-folders

# Get number of samples per family
list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names
no_imgs = []  # No. of samples per family
for i in range(len(list_fams)):
    os.chdir(list_fams[i])
    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png'
    no_imgs.append(len1)
    os.chdir('..')
num_samples = np.sum(no_imgs)  # total number of all samples

# Compute the labels
y = np.zeros(num_samples)
pos = 0
label = 0
for i in no_imgs:
    print ("Label:%2d\tFamily: %15s\tNumber of images: %d" % (label, list_fams[label], i))
    for j in range(i):
        y[pos] = label
        pos += 1
    label += 1
num_classes = label
# Loading Generated Simhash
gs_data = os.path.join("/content/drive/MyDrive/Jahez_Vinod_2023/DMD(MainProject)/GAN/GeneratedGrayscale")

folders = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# capturing training data and labels into respective lists
gs_images = []
gs_labels = []

for folder in folders:
    sub_folder = os.path.join(gs_data, folder)
    print(sub_folder)
    for file_ in os.listdir(sub_folder):
        img_path = os.path.join(sub_folder, file_)
        img = image.load_img(img_path, target_size=(224, 224))
        img_array = image.img_to_array(img)
        img_array = img_array[:, :, :3]
        gs_images.append(img_array)
        gs_labels.append(folder)

# Splitting the generated Grayscale Images into test and train
x_gs_train, x_gs_test, y_gs_train, y_gs_test = train_test_split(gs_images, gs_labels, test_size=0.2, random_state=42)

# Check the shapes of the resulting datasets
print("Training data shape:", x_gs_train.shape)
print("Training label shape:", y_gs_train.shape)
print("Testing data shape:", x_gs_test.shape)
print("Testing label shape:", y_gs_test.shape)

# Label Encoding
le = preprocessing.LabelEncoder()
le.fit(y_gs_train)
y_gs_train_encoded = le.transform(y_gs_train) #train labels
le.fit(y_gs_test)
y_gs_test_encoded = le.transform(y_gs_test) #test labels

# One-hot encoding the labels 
y_gs_train_encoded = tf.keras.utils.to_categorical(y_gs_train_encoded, num_classes=9)
y_gs_test_encoded = tf.keras.utils.to_categorical(y_gs_test_encoded, num_classes=9)

# Saving the test set
hex_image_arr = x_gs_test
hex_npy = "hex_image.npy"
np.save(hex_npy, hex_image_arr)

# Entropy
# Loading Generated Entropy
eg_data = os.path.join("/content/drive/MyDrive/Jahez_Vinod_2023/DMD(MainProject)/GAN/GeneratedEntropy")

folders = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# capturing training data and labels into respective lists
eg_images = []
eg_labels = []

for folder in folders:
    sub_folder = os.path.join(eg_data, folder)
    print(sub_folder)
    for file_ in os.listdir(sub_folder):
        img_path = os.path.join(sub_folder, file_)
        img = image.load_img(img_path, target_size=(224, 224))
        img_array = image.img_to_array(img)
        img_array = img_array[:, :, :3]
        eg_images.append(img_array)
        eg_labels.append(folder)

# Splitting the generated entropy Images into test and train
x_eg_train, x_eg_test, y_eg_train, y_eg_test = train_test_split(eg_images, eg_labels, test_size=0.2, random_state=42)

# Check the shapes of the resulting datasets
print("Training data shape:", x_eg_train.shape)
print("Training label shape:", y_eg_train.shape)
print("Testing data shape:", x_eg_test.shape)
print("Testing label shape:", y_eg_test.shape)

# Label Encoding
le = preprocessing.LabelEncoder()
le.fit(y_eg_train)
y_eg_train_encoded = le.transform(y_eg_train) #train labels
le.fit(y_eg_test)
y_eg_test_encoded = le.transform(y_eg_test) #test labels

# One-hot encoding the labels 
y_eg_train_encoded = tf.keras.utils.to_categorical(y_eg_train_encoded, num_classes=9)
y_eg_test_encoded = tf.keras.utils.to_categorical(y_eg_test_encoded, num_classes=9)

# Saving the test set
eg_image_arr = x_eg_test[:300]
eg_npy = "eg_image.npy"
np.save(eg_npy, eg_image_arr)
y_eg_test_encoded = y_eg_test_encoded[:300]

# Simhash
# Loading Generated Simhash
sh_data = os.path.join("/content/drive/MyDrive/Jahez_Vinod_2023/DMD(MainProject)/GAN/GeneratedSimhash")

folders = ['Lollipop', 'Kelihos_ver3', 'Gatak', 'Kelihos_ver1', 'Obfuscator.ACY', 'Simda', 'Tracur', 'Vundo', 'Ramnit']

# capturing training data and labels into respective lists
sh_images = []
sh_labels = []

for folder in folders:
    sub_folder = os.path.join(sh_data, folder)
    print(sub_folder)
    for file_ in os.listdir(sub_folder):
        img_path = os.path.join(sub_folder, file_)
        img = image.load_img(img_path, target_size=(224, 224))
        img_array = image.img_to_array(img)
        img_array = img_array[:, :, :3]
        sh_images.append(img_array)
        sh_labels.append(folder)

# Splitting the generated entropy Images into test and train
x_sh_train, x_sh_test, y_sh_train, y_sh_test = train_test_split(sh_images, sh_labels, test_size=0.2, random_state=42)

# Check the shapes of the resulting datasets
print("Training data shape:", x_sh_train.shape)
print("Training label shape:", y_sh_train.shape)
print("Testing data shape:", x_sh_test.shape)
print("Testing label shape:", y_sh_test.shape)

# Label Encoding
le = preprocessing.LabelEncoder()
le.fit(y_sh_train)
y_sh_train_encoded = le.transform(y_sh_train) #train labels
le.fit(y_eg_test)
y_sh_test_encoded = le.transform(y_sh_test) #test labels

# One-hot encoding the labels 
y_sh_train_encoded = tf.keras.utils.to_categorical(y_sh_train_encoded, num_classes=9)
y_sh_test_encoded = tf.keras.utils.to_categorical(y_sh_test_encoded, num_classes=9)

# Saving the test set
sh_image_arr = x_sh_test
sh_npy = "sh_image.npy"
np.save(sh_npy, sh_image_arr)


#              L O A D I N G  P R O P O S E D  M O D E L

# Loading the concatenated model (GS||EG||SH)
model = load_model("/content/drive/MyDrive/Jahez_Vinod_2023/Big2015/Merge/Models/GS_EG_SH_vgg(concat[conv]).keras")
model.summary()

test_images = [np.load('hex_image.npy'),np.load('eg_image.npy'),np.load('sh_image.npy')]



